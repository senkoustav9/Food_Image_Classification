{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqMBmoyYTuDU"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhBcczgJFsay"
      },
      "outputs": [],
      "source": [
        "#code to mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UocrO8hOFsaz"
      },
      "source": [
        "## Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idl8fUyrTq1f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "    print(\"Downloading helper functions...\")\n",
        "    !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "else:\n",
        "    print(\"Helper functions file already exists, skipping download...\")\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys, load_and_prep_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KGcEYRNtS6mo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLqBh4nJFsa1"
      },
      "source": [
        "## Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OWT3JkoT7qH"
      },
      "outputs": [],
      "source": [
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n",
        "                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n",
        "                                             shuffle_files=False, # shuffle files on download?\n",
        "                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n",
        "                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QNpZWGvFsa4"
      },
      "source": [
        "## Accessing & Visualizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaX8ZxxoT7tH"
      },
      "outputs": [],
      "source": [
        "# Features of Food101 TFDS\n",
        "ds_info.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ii4X-EGT7wt"
      },
      "outputs": [],
      "source": [
        "# Get class names\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "train_one_sample = train_data.take(1)\n",
        "train_one_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qciw9MglU0YQ",
        "outputId": "c71e5c03-cb95-47d7-c6ab-cd289cd06931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Image shape: (512, 512, 3)\n",
            "  Image dtype: <dtype: 'uint8'>\n",
            "  Target class from Food101 (tensor form): 56\n",
            "  Class name (str form): huevos_rancheros\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# Output info about our training sample\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape}\n",
        "  Image dtype: {image.dtype}\n",
        "  Target class from Food101 (tensor form): {label}\n",
        "  Class name (str form): {class_names[label.numpy()]}\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbCDnROFsa9"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac9p-UZsVSqW"
      },
      "outputs": [],
      "source": [
        "# Make a function for preprocessing images\n",
        "def preprocess_img(image, label, img_shape=224):\n",
        "  image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n",
        "  return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ozpj8BvVSuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e29c04-5b24-4811-a45f-bce3d266380d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (224, 224, 3),\n",
            "Datatype: <dtype: 'float32'>\n"
          ]
        }
      ],
      "source": [
        "# Preprocess a single sample image and check the outputs\n",
        "preprocessed_img = preprocess_img(image, label)[0]\n",
        "print(f\"Shape: {preprocessed_img.shape},\\nDatatype: {preprocessed_img.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYEbBhZFVS2j"
      },
      "outputs": [],
      "source": [
        "# Map preprocessing function to training data (and paralellize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Map prepreprocessing function to test data\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Turn test data into batches (don't need to shuffle)\n",
        "test_data = test_data.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYTTn7mTWEMk"
      },
      "outputs": [],
      "source": [
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYt-x9XJFsa_"
      },
      "source": [
        "## Create modelling callbacks & Setting mixed precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HPqR0urWERT"
      },
      "outputs": [],
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      montior=\"val_accuracy\", # save the model weights with best validation accuracy\n",
        "                                                      save_best_only=True, # only save the best weights\n",
        "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
        "                                                      verbose=1) # don't print out whether or not model is being saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzktXcpvWEU2"
      },
      "outputs": [],
      "source": [
        "# Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision\n",
        "mixed_precision.global_policy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctYXx4TRFsbA"
      },
      "source": [
        "## Build feature extraction model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_OZJNnXDTL"
      },
      "outputs": [],
      "source": [
        "# Create base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\", dtype=tf.float16)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dropout(.3)(x)\n",
        "x = layers.Dense(len(class_names))(x) # want one output neuron per class\n",
        "\n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpAVxCbnXJoj"
      },
      "outputs": [],
      "source": [
        "# Check out our model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVE-alTyX5jl"
      },
      "outputs": [],
      "source": [
        "# Fit the model with callbacks\n",
        "history_feature_extract = model.fit(train_data,\n",
        "                                    epochs=5,\n",
        "                                    steps_per_epoch=len(train_data),\n",
        "                                    validation_data=test_data,\n",
        "                                    validation_steps=int(0.15 * len(test_data)),\n",
        "                                    callbacks=[create_tensorboard_callback(\"training_logs\",\n",
        "                                                                           \"efficientnetb0_101_classes_all_data_feature_extract\"),\n",
        "                                               model_checkpoint]\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX-bdnNoX5nL"
      },
      "outputs": [],
      "source": [
        "# Evaluate model (unsaved version) on whole test dataset\n",
        "results_feature_extract_model = model.evaluate(test_data)\n",
        "results_feature_extract_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opilPywWX5te"
      },
      "outputs": [],
      "source": [
        "!ls model_checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GllUY_YGYz_h"
      },
      "outputs": [],
      "source": [
        "# Create save path to drive\n",
        "save_dir = \"drive/MyDrive/food_app/extractor/\"\n",
        "os.makedirs(save_dir) # Make directory if it doesn't exist\n",
        "\n",
        "# Save model\n",
        "model.save(save_dir)\n",
        "model.save(\"/content/drive/MyDrive/food_app/ExtractorModel.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggGoUhtoZ4dC"
      },
      "outputs": [],
      "source": [
        "loaded_saved_model = tf.keras.models.load_model(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icEwOYPvFsbF"
      },
      "source": [
        "## Preparing our model's layers for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF7uFMoZdAQy"
      },
      "outputs": [],
      "source": [
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
        "                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n",
        "\n",
        "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
        "checkpoint_path = \"fine_tune_checkpoints/\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKGEVQCvcdEf"
      },
      "outputs": [],
      "source": [
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, # print out when learning rate goes down\n",
        "                                                 min_lr=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhJgBfaQdhps"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "loaded_saved_model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n",
        "                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n",
        "                        metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdgeCauhdhsq"
      },
      "outputs": [],
      "source": [
        "# Start to fine-tune (all layers)\n",
        "history_fine_tuning = loaded_saved_model.fit(train_data,\n",
        "                                             epochs=20, # fine-tune for a maximum of 100 epochs\n",
        "                                             steps_per_epoch=len(train_data),\n",
        "                                             validation_data=test_data,\n",
        "                                             validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n",
        "                                             callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # track the model training logs\n",
        "                                             model_checkpoint, # save only the best model during training\n",
        "                                             early_stopping, # stop model after X epochs of no improvements\n",
        "                                             reduce_lr]) # reduce the learning rate after X epochs of no improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb5xQLjmdhv_"
      },
      "outputs": [],
      "source": [
        "## Save model to Google Drive\n",
        "loaded_saved_model.save(\"/content/drive/MyDrive/food_app/fine_tuning/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbGgyxJQdhzJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate mixed precision trained loaded model\n",
        "results_loaded_gs_model_fine_tuned = loaded_saved_model.evaluate(test_data)\n",
        "results_loaded_gs_model_fine_tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gelrVLKCdh2_"
      },
      "outputs": [],
      "source": [
        "loaded_saved_model.save(\"/content/drive/MyDrive/food_app/FinalModel.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7F2e8wTspRP"
      },
      "outputs": [],
      "source": [
        "# Load model previously saved above\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/food_app/FinalModel.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KabBTpRdh6f"
      },
      "outputs": [],
      "source": [
        "# Evaluate mixed precision trained loaded model\n",
        "results_loaded_model_fine_tuned = model.evaluate(test_data)\n",
        "results_loaded_model_fine_tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8iHngDbmzkt"
      },
      "source": [
        "## Model Evaluation and Visualization\n",
        "#### SKlearn's Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxZsqnHjhqNZ"
      },
      "outputs": [],
      "source": [
        "pred_probs = model.predict(test_data, verbose=1)\n",
        "pred_classes = pred_probs.argmax(axis=1)\n",
        "y_labels = []\n",
        "for images, labels in test_data.unbatch():\n",
        "    y_labels.append(labels.numpy())\n",
        "sklearn_acc = accuracy_score(y_labels, pred_classes)\n",
        "sklearn_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCOWAH1Omzkw"
      },
      "source": [
        "## Predicting User Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcT9C2vAmzk1"
      },
      "outputs": [],
      "source": [
        "def pred_plot_custom(folder_path):\n",
        "  import os\n",
        "\n",
        "  custom_food_images = [folder_path + img_path for img_path in os.listdir(folder_path)]\n",
        "  fig, a = plt.subplots(len(custom_food_images),2, figsize=(15, 5 * len(custom_food_images)))\n",
        "  i = 0\n",
        "  # Load and preprocess the image\n",
        "  img = load_and_prep_image(img, scale=False)\n",
        "\n",
        "  # Make predictions using the model\n",
        "  pred_prob = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class with the highest probability\n",
        "  pred_class_index = pred_prob.argmax()\n",
        "  pred_class = class_names[pred_class_index]\n",
        "  pred_accuracy = pred_prob[0, pred_class_index]\n",
        "\n",
        "  # Now, pred_class contains the predicted class label, and pred_accuracy contains its corresponding probability.\n",
        "  print(f\"Image: {img}, Predicted Class: {pred_class}, Accuracy: {pred_accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFnNPj_Wmzk2"
      },
      "outputs": [],
      "source": [
        "# pred_plot_custom(\"/content/drive/MyDrive/food_app/images/food_img/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}